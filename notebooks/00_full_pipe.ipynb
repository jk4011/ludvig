{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df5c4f2a",
   "metadata": {},
   "source": [
    "# 0. Setup (Don't unfold!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f6ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.chdir('../')\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"Marigold\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import jhutil; jhutil.color_log(1111, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac1d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "vggt = True\n",
    "if vggt:\n",
    "    sys.argv = [\n",
    "        \"ludvig_uplift.py\", \n",
    "        \"--colmap_dir\", \"./dataset/llff_data/fern/vggt/\", \n",
    "        \"--gs_source\", \"./dataset/llff_data/fern/vggt/point_cloud/iteration_0/point_cloud.ply\", \n",
    "        \"--config\", \"configs/dif_NVOS.yaml\", \n",
    "        \"--height\", \"1199\", \n",
    "        \"--width\", \"1600\", \n",
    "        \"--tag\", \"fern\"\n",
    "    ]\n",
    "else:\n",
    "    sys.argv = [\n",
    "        \"ludvig_uplift.py\", \n",
    "        \"--colmap_dir\", \"./dataset/llff_data/fern/\", \n",
    "        \"--gs_source\", \"./dataset/llff_data/fern/gs/point_cloud/iteration_30000/point_cloud.ply\", \n",
    "        \"--config\", \"configs/dif_NVOS.yaml\", \n",
    "        \"--height\", \"1199\", \n",
    "        \"--width\", \"1600\", \n",
    "        \"--tag\", \"fern\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e34ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ludvig_uplift import *\n",
    "\n",
    "args = parse_args()\n",
    "reproducibility(0)\n",
    "model = LUDVIGUplift(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb42e5c5",
   "metadata": {},
   "source": [
    "# 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0c043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "print(\"Uplifting features...\")\n",
    "directory = model.config['feature'].pop(\n",
    "    'directory',\n",
    "    os.path.join(model.colmap_dir, 'images')\n",
    ")\n",
    "dataset = config_to_instance(\n",
    "    directory=directory,\n",
    "    gaussian=model.gaussian,\n",
    "    cameras=model.colmap_cameras,\n",
    "    render_fn=model.render,\n",
    "    scene=model.scene,\n",
    "    height=model.img_height,\n",
    "    width=model.img_width,\n",
    "    **model.config.feature,\n",
    ")\n",
    "loader = iter(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8123c97",
   "metadata": {},
   "source": [
    "# 2. Uplift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896f6c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, _ = uplifting(\n",
    "    loader,\n",
    "    model.gaussian,\n",
    "    prune_gaussians=model.config.get(\"prune_gaussians\", None),\n",
    ")\n",
    "if model.config.get('normalize', False):\n",
    "    print(\"l2-normalizing uplifted features.\")\n",
    "    features /= features.norm(dim=1, keepdim=True) + 1e-6\n",
    "print(\n",
    "    f\"Total time for preprocessing + uplifting {len(model.colmap_cameras)} images: {round(time()-t0)}s\"\n",
    ")\n",
    "model.features = features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e89c395",
   "metadata": {},
   "source": [
    "# 3. HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72eb014",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "# load eval_fn\n",
    "########################################################\n",
    "\n",
    "from evaluation.spin_nvos.diffusion import SegmentationDiffusionNVOS\n",
    "\n",
    "os.makedirs(model.logdir, exist_ok=True)\n",
    "cfg_path = os.path.join(model.logdir, \"config.yaml\")\n",
    "yaml.dump(model.config, open(cfg_path, \"w\"))\n",
    "eval_kwargs = model.config.get(\"evaluation\", dict())\n",
    "\n",
    "eval_fn: SegmentationDiffusionNVOS = config_to_instance(\n",
    "    gaussian=model.gaussian,\n",
    "    features=model.features,\n",
    "    render_fn=model.render,\n",
    "    render_rgb=model.render_rgb,\n",
    "    logdir=model.logdir,\n",
    "    image_dir=model.colmap_dir,\n",
    "    colmap_cameras=model.colmap_cameras,\n",
    "    scene=model.scene,\n",
    "    height=model.img_height,\n",
    "    width=model.img_width,\n",
    "    **model.config.evaluation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092d3dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = eval_fn.hyperparameter_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658106cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion.segmentation import GraphDiffusionSeg\n",
    "from utils.graph import energy_fn\n",
    "\n",
    "def graph_call(graph:GraphDiffusionSeg, features):\n",
    "    features = graph.normalize_features(features)\n",
    "\n",
    "    if graph.initial_features is None:\n",
    "        graph.compute_initial_features()\n",
    "        graph.mask = graph.initial_features.squeeze() > 0\n",
    "        graph.precompute_similarities(features)\n",
    "    \n",
    "    # similarities = graph.compute_similarities()\n",
    "    similarities = energy_fn(\n",
    "        graph.similarities, graph.feature_bandwidth, graph.mask\n",
    "    )\n",
    "    graph.compute_regularizer(features)\n",
    "    similarities *= torch.sqrt(\n",
    "        graph.reg_similarities[graph.knn_neighbor_indices] * graph.reg_similarities[:, None]\n",
    "    )\n",
    "    \n",
    "    diffused_features = graph.run_diffusion(similarities, binarize=1e-5)\n",
    "    diffused_features = (diffused_features>0) * graph.reg_similarities[:,None].type(torch.float32)\n",
    "    \n",
    "    return diffused_features, graph.reg_similarities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3958d34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.linspace(1, 4, 5)\n",
    "# np.linspace(1, 4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c057ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "\n",
    "frange = np.arange(1, 5)\n",
    "grange = np.arange(1, 5)\n",
    "k_best = 0\n",
    "f_best = 2\n",
    "g_best = 2\n",
    "results = []\n",
    "best_iou = 0\n",
    "param_combinations = list(product(frange, grange))\n",
    "with tqdm(total=len(param_combinations)) as pbar:\n",
    "    for f, g in param_combinations:\n",
    "        eval_fn.graph.feature_bandwidth = 2.0**f\n",
    "        eval_fn.graph.reg_bandwidth = 2.0**g\n",
    "        eval_fn.manifold_features, _ = graph_call(eval_fn.graph, eval_fn.features)\n",
    "        cur_iou, k_iou = eval_fn.segment_and_evaluate(\n",
    "            eval_fn.manifold_features,\n",
    "            save=False,\n",
    "            use_sam=eval_fn.sam_model is not None,\n",
    "        )\n",
    "        if cur_iou > best_iou:\n",
    "            best_iou = cur_iou\n",
    "            k_best = k_iou\n",
    "            f_best = 2.0**f\n",
    "            g_best = 2.0**g\n",
    "        pbar.update(1)\n",
    "        results.append((f, g, cur_iou))\n",
    "eval_fn.graph.feature_bandwidth = f_best\n",
    "eval_fn.graph.reg_bandwidth = g_best\n",
    "eval_fn.graph.trace_name = eval_fn.trace_name\n",
    "eval_fn.manifold_features, eval_fn.reg_similarities = eval_fn.graph.__call__(eval_fn.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10faf769",
   "metadata": {},
   "source": [
    "# 4. Render mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb25a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_fn.evaluate(k_best, f_best, g_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cd203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.spin_nvos.base import *\n",
    "\n",
    "features = eval_fn.manifold_features\n",
    "ev_name = eval_fn.ev_name\n",
    "img_name = ev_name.split(\"/\")[-1]\n",
    "camera = next(\n",
    "    cam\n",
    "    for cam in eval_fn.colmap_cameras\n",
    "    if cam.image_name == eval_fn.mask_to_img[img_name]\n",
    ")\n",
    "\n",
    "gt_path = eval_fn.gtpath_from_name(ev_name)\n",
    "gt_img = Image.open(gt_path)\n",
    "\n",
    "anchor = eval_fn.render_fn(features.repeat(1, 3), camera)[:1]\n",
    "\n",
    "anchor = viz_normalization(anchor, dim=range(len(anchor.shape)))\n",
    "_img_up = resize(anchor, (gt_img.size[1], gt_img.size[0])).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bbe0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "_img_up.chans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce938ae7",
   "metadata": {},
   "source": [
    "# 5. Get IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70b6a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.evaluation import segmentation_loop\n",
    "\n",
    "# best_iou, mask_best, _, _ = segmentation_loop(\n",
    "#     _img_up, gt_img, k_best, metric=\"iou\"\n",
    "# )\n",
    "# print(\"IoU:\", round(best_iou, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c08b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.evaluation import to_pil, iou\n",
    "\n",
    "mask_2d = _img_up > (1 - k_best / 100)\n",
    "mask_best_iou = to_pil(mask_2d)\n",
    "img_arr, gt_img_arr = np.array(mask_best_iou), np.array(gt_img)\n",
    "img_arr = img_arr // max(img_arr.max(), 1)\n",
    "gt_img_arr = gt_img_arr // gt_img_arr.max()\n",
    "best_iou = iou(img_arr, gt_img_arr, class_label=1)\n",
    "\n",
    "print(\"IoU:\", round(best_iou, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b0f3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_2d.chans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b3b64b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd589e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f6d29a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ludvig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
