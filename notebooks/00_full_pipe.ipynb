{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60f6ff2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41m\u001b[30m 1111 \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.chdir('../')\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"Marigold\")\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import jhutil; jhutil.color_log(1111, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ac1d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = [\n",
    "    \"ludvig_uplift.py\", \n",
    "    \"--colmap_dir\", \"./dataset/llff_data/fern/\", \n",
    "    \"--gs_source\", \"./dataset/llff_data/fern/gs/point_cloud/iteration_30000/point_cloud.ply\", \n",
    "    \"--config\", \"configs/dif_NVOS.yaml\", \n",
    "    \"--height\", \"1199\", \n",
    "    \"--width\", \"1600\", \n",
    "    \"--tag\", \"fern\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93e34ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading camera 20/20\n",
      "735471 Gaussians.\n"
     ]
    }
   ],
   "source": [
    "from ludvig_uplift import *\n",
    "\n",
    "args = parse_args()\n",
    "reproducibility(0)\n",
    "model = LUDVIGUplift(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb42e5c5",
   "metadata": {},
   "source": [
    "# 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf0c043d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uplifting features...\n",
      "  \u001b[32m cccc  \"cache file found, skipping dino_extract\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "print(\"Uplifting features...\")\n",
    "directory = model.config['feature'].pop(\n",
    "    'directory',\n",
    "    os.path.join(model.colmap_dir, 'images')\n",
    ")\n",
    "dataset = config_to_instance(\n",
    "    directory=directory,\n",
    "    gaussian=model.gaussian,\n",
    "    cameras=model.colmap_cameras,\n",
    "    render_fn=model.render,\n",
    "    scene=model.scene,\n",
    "    height=model.img_height,\n",
    "    width=model.img_width,\n",
    "    **model.config.feature,\n",
    ")\n",
    "loader = iter(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8123c97",
   "metadata": {},
   "source": [
    "# 2. Uplift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "896f6c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:03,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for uplifting 20 views: 3.2s\n",
      "Keeping 367735 points out of 735471.\n",
      "Total time for preprocessing + uplifting 20 images: 6s\n"
     ]
    }
   ],
   "source": [
    "features, _ = uplifting(\n",
    "    loader,\n",
    "    model.gaussian,\n",
    "    prune_gaussians=model.config.get(\"prune_gaussians\", None),\n",
    ")\n",
    "if model.config.get('normalize', False):\n",
    "    print(\"l2-normalizing uplifted features.\")\n",
    "    features /= features.norm(dim=1, keepdim=True) + 1e-6\n",
    "print(\n",
    "    f\"Total time for preprocessing + uplifting {len(model.colmap_cameras)} images: {round(time()-t0)}s\"\n",
    ")\n",
    "model.features = features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e89c395",
   "metadata": {},
   "source": [
    "# 3. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72eb014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_IncompatibleKeys(missing_keys=['mask_decoder.hf_token.weight', 'mask_decoder.hf_mlp.layers.0.weight', 'mask_decoder.hf_mlp.layers.0.bias', 'mask_decoder.hf_mlp.layers.1.weight', 'mask_decoder.hf_mlp.layers.1.bias', 'mask_decoder.hf_mlp.layers.2.weight', 'mask_decoder.hf_mlp.layers.2.bias', 'mask_decoder.compress_vit_feat.0.weight', 'mask_decoder.compress_vit_feat.0.bias', 'mask_decoder.compress_vit_feat.1.weight', 'mask_decoder.compress_vit_feat.1.bias', 'mask_decoder.compress_vit_feat.3.weight', 'mask_decoder.compress_vit_feat.3.bias', 'mask_decoder.embedding_encoder.0.weight', 'mask_decoder.embedding_encoder.0.bias', 'mask_decoder.embedding_encoder.1.weight', 'mask_decoder.embedding_encoder.1.bias', 'mask_decoder.embedding_encoder.3.weight', 'mask_decoder.embedding_encoder.3.bias', 'mask_decoder.embedding_maskfeature.0.weight', 'mask_decoder.embedding_maskfeature.0.bias', 'mask_decoder.embedding_maskfeature.1.weight', 'mask_decoder.embedding_maskfeature.1.bias', 'mask_decoder.embedding_maskfeature.3.weight', 'mask_decoder.embedding_maskfeature.3.bias'], unexpected_keys=[])\n",
      "Default evaluation: dataset/llff_masks/masks/fern/IMG_4027\n",
      "  \u001b[32m cccc  \"cache file found, skipping query_neighbors\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "# load eval_fn\n",
    "########################################################\n",
    "\n",
    "from evaluation.spin_nvos.diffusion import SegmentationDiffusionNVOS\n",
    "\n",
    "os.makedirs(model.logdir, exist_ok=True)\n",
    "cfg_path = os.path.join(model.logdir, \"config.yaml\")\n",
    "yaml.dump(model.config, open(cfg_path, \"w\"))\n",
    "eval_kwargs = model.config.get(\"evaluation\", dict())\n",
    "\n",
    "eval_fn: SegmentationDiffusionNVOS = config_to_instance(\n",
    "    gaussian=model.gaussian,\n",
    "    features=model.features,\n",
    "    render_fn=model.render,\n",
    "    render_rgb=model.render_rgb,\n",
    "    logdir=model.logdir,\n",
    "    image_dir=model.colmap_dir,\n",
    "    colmap_cameras=model.colmap_cameras,\n",
    "    scene=model.scene,\n",
    "    height=model.img_height,\n",
    "    width=model.img_width,\n",
    "    **model.config.evaluation,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c0bfd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6/6 | Bandwidths: 4.0, 16.0  IoU: 0.857 --  Best IoU: 0.891  Best bandwidths: 2.0, 16.0\n"
     ]
    }
   ],
   "source": [
    "args = eval_fn.hyperparameter_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0b9e2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature and regularization bandwiths, chosen based on IoU with SAM mask: 2.0 16.0\n",
      "IoU: 0.843\n"
     ]
    }
   ],
   "source": [
    "eval_fn.evaluate(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c460d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd589e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f6d29a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ludvig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
